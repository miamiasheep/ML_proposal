%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Eric Lee adapted from
%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=letter, fontsize=12pt]{scrartcl} % letter paper and 12pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage{times}
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{\thepage} % Page numbering 
\fancyfoot[R]{} % Empty
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\usepackage{graphicx} % Required for the inclusion of images


\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\horrule{2pt} \\[0.4cm] % Thin top horizontal rule
{\LARGE Link Prediction in Social Network} \\ % The assignment title
\horrule{1pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{\large{Eric L. Lee, Shu-Hao Chang, Yu-Cheng Weng, Can Jiang}\\
  \normalsize{\{lee3388,danielll, weng47, Jiang607\}@purdue.edu.}
} % Your name
\date{} % I do not think we need a date

\begin{document}

\maketitle % Print the title

\begin{abstract}
  Link prediction is one of the core problems of network-structure data. Some heuristic work pretty well in network kind of data such as katz index\cite{katz}, common neighbor, ... etc. However, because the heuristic method highly depends on the assumuption we make in the data set, it is not a general solution. What we want to do is propose a machine learning model that can work in the network-structured data. Recent years, there are some works focusing on these solutions. Zhang and Chen \cite{lpnn} \cite{wlnn} focused on solving these problems by labeling nodes in an enclosed subgraph. We want to do experiments to test all the methods that proposed in recent years in different network and do some data analytics about these methods. Besides, we aims at proposing a new machine learning model that can achieve better result.
\end{abstract}

\section{Introduction}
Given two nodes in a graph. Link prediction is a task to predict the probability whether there will be a link. It can benefit lots of application such as friend recommendation in social network, movie recommendation, and metabolic network reconstruction.

Although it is an important problem, it is not a trivial problem for machine learning. One of the most difficult problem is to model the geometrical information of a certain node. Unlike common machine learning problems that already have specific feature vector, it is hard to find a feature vector to describe the situation of a node.

\subsection {Related Works}
There are already some existing works about link prediction. We organized these methods into three categories: Heuristics, latent feature models, and  Labeling nodes in a enclosed subgraph.

\subsubsection{Heuristic Method}
The most straight forward method is to design heuristics.
In network structured data, there are some famous heuristics to make prediction. One of famous heuristic is common neighbors. It is proved to be a very successful and there are lots of heuristics extend common neighbors. For example, jaccard index is an intuitive and successful idea. In 2003, Adamic and Adar \cite{adar} proposed an index that decrease the contribution of the nodes having high degrees and achieve a better performance. In 2009, based on the same idea, Zhou et al. \cite{ra} propose Resource Allocation index for link prediction. There are also heuristics for other kind of link prediction problem. For example, Preferential Attachment \cite{pa} is a popular index for road network prediction.

The heuristic mentioned above only considers the node that are one hop away (common neighbor, Jaccard, Preferential Attachment) or two hop away(Adamic, Resource Allocation) from the node we want to predict. There are also some methods involve nodes that is high distance away from the target node. For example, Katz \cite{katz} apply exponential decay to distance to the nodes that has at least one path to arrive. Local pagerank uses random walk to find a stable state when the start point is the target node.  

\subsubsection {Latent Feature Model}
One of a successful solution is to train latent features for each node. One successful exmple is matrix factorzation. Matrix Factorization is a method that have a very good performance in the field of bipartite graph link prediction. Koren et al. proposed a matrix factorization \cite{mf} method minimizing square error and have a very good performance in terms of Root Mean Square Error(RMSE) in the netflix competition. In 2012, Rendle et al. \cite{bprmf} proposed Bayesian Personalized Ranking to optimze Area Under receiver operating charateristics Curve(AUC) and solve ranking problem while using matrix factorization. This methods achieve a very good result in link prediction in bipartite graph. However, these methods are specificially design for link prediction in bipartite graph. 

\subsubsection {Labeling node in an enclosed subgraph}
In 2017, Zhang et al. proposed a novel machine learning method. The hardest part to design a matching learning model is to extract geographical feature that can describe the geometry information for a certain node. Zhang proposed a novel method to solve the problems. He first divide the network into several enclosed subgraph. For each subgraph, he uses Weisfeiler-Lehman (WL) graph labeling to label nodes. The magic of WL graph labeling is that it preserve the order of each node in each iteration.

After we labeling the nodes in the enclosed subgraph, we can enumerate all the nodes and get a adjancency matrix and use this matrix to be the feature vectors. The paper shows their result outperform most of previous method if they train their model with convolutional neural network.


\section{Research Plan}

\subsection{Data Acquisition and Evaluation}
The main data source of this project will be from SNAP (Stanford Network Analysis Project).
For each Network,  for each node we randomly remove 10\% of edges as testing set. However, the network provides the time establishing each link, we will remove latest 10\% edges as testing set. For each node, we will rank a candidate list that is a ranking of remaining potential node. In this way, we can calculate F1@k, Recall@k, Accuracy@k, AUC, MAP@k, ... metrics that related to ranking. 

\subsection {Research Direction}
We will first implement the method we metion in the related work section and do some data analysis of each model. After that, we will do some research topic list in the following. 

\subsubsection {Ensembling Heuristics}
The first step we want to do is to explore each heuristic node. In this way we cannot only do some data analysis but also build a very intuitive baseline. 
For the data analysis part, what we want to know is the following two things: \\
1. What heuristic is better in different network? \\
2. Is any combination of the heuristic can achieve better result? \\

For the baseline model part, we want to use a machine learning model and use each heuristics I mentioned above as features. However, it is not a trivial problem. Degrees if nodes are much smaller than the nodes in the graph which means the data is very imbalance. Negative data is much more than the positive one.\\
There are lots of topic that we want to explore: \\
1. How can we sample negative data? Will it affect result a lot? \\
2. If negative sampling affect a lot to performance, can we find a good way to sample negative data? \\
3. What machine learning models can achieve better performance? \\

\subsubsection {Leverage latent feature models}
To our best knowledge, there is no latent feature models apply on general link prediction problem directly. However, there are lots of latent feature models aims at solving community detection, role detection in social network. For example, Yang and Leskovec \cite{bigclam} propose BIGCLAM that can do overlapping community detection. 

One of our direction is to incorporate these kind of models and design a new model that considering the latent features. 

\subsubsection {Use Meta Information of nodes}
We believe the meta information in each node can further improve the result of link prediction. One simple and naive solution is to add this information as feature. The other is to use the information to enhance the graph labeling. Currently, we have no concrete solution about this. But we will keep thinking in this semester.

\subsubsection {Modeling reciprocalness}
One interesting fact about social network is that if there are link between A and B. It is not only because A likes B but also B likes A. We believe if we consider the fact, we can further improve the performance.

%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliographystyle{apalike}
\bibliography{sample}


\end{document}
